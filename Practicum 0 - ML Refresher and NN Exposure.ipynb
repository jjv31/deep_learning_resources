{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc2e236-b4fe-4cb7-8b34-31743cf1d86e",
   "metadata": {},
   "source": [
    "# ML Refresher | Neural Network Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d34b8-896c-46c8-be3e-02e2d245987c",
   "metadata": {},
   "source": [
    "### Practicum Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5d13e-2f32-4d4e-aa90-1bc45ad7df94",
   "metadata": {},
   "source": [
    "We'll go through the machine learning loop to (i) preprocess a real datast and (ii) train it to predict GBH incidents using a random forest. Upon building the random forest, we'll then construct a neural network to give you an understanding of how training a deep learning model works. In doing so, we'll be executing each major process of the machine learning loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bcad6-8ad2-4c00-8e69-e7891558df88",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/model_building/ml_wheel.jpg\" width=\"25%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea2254-f239-420c-862a-f6a069a192e0",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11beaa-51d7-45ea-9baa-d36bdf7ad774",
   "metadata": {},
   "source": [
    "The hyperparameters for the random forest appear below. Though in this practicum, our primary focus will be the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a1336-4ff6-4b34-ba16-97ce32b15a2f",
   "metadata": {},
   "source": [
    "#### Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d5782-7571-45af-a916-e6c8cedf8660",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li> <strong>n_estimators.</strong> The number of trees in the forest. </li>\n",
    "  <li> <strong>criterion:</strong> The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain. </li>\n",
    "  <li> <strong>max_depth.</strong> The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. </li>\n",
    "  <li> <strong>min_samples_split.</strong> The minimum number of samples required to split an internal node. </li>\n",
    "  <li> <strong>min_samples_leaf.</strong> The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression. </li>\n",
    "  <li> <strong>min_weight_fraction_leaf.</strong> The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided. </li>\n",
    "  <li> <strong>max_features.</strong> The number of features to consider when looking for the best split. </li>\n",
    "  <li> <strong>max_leaf_nodes.</strong> Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes. </li>\n",
    "  <li> <strong>min_impurity_decrease.</strong> A node will be split if this split induces a decrease of the impurity greater than or equal to this value. </li>\n",
    "  <li> <strong>min_impurity_split.</strong> Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf. </li>\n",
    "  <li> <strong>bootstrap.</strong> Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree. </li>\n",
    "  <li> <strong>oob_score.</strong> Whether to use out-of-bag samples to estimate the generalization accuracy. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f295978-a758-4277-9099-27128570780c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0 | Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f086bda8-d5b1-458d-8046-3f70f3412a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d479b3e8-2f33-4a40-bc30-1a68b2ba74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_safe(src, dst, max_len=200):\n",
    "    \"\"\"Copy files, skip long paths\"\"\"\n",
    "    skipped = 0\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        rel_path = os.path.relpath(root, src)\n",
    "        dst_root = os.path.join(dst, rel_path) if rel_path != '.' else dst\n",
    "        if len(dst_root) < max_len:\n",
    "            os.makedirs(dst_root, exist_ok=True)\n",
    "            for file in files:\n",
    "                dst_file = os.path.join(dst_root, file)\n",
    "                if len(dst_file) < max_len:\n",
    "                    try: shutil.copy2(os.path.join(root, file), dst_file)\n",
    "                    except: skipped += 1\n",
    "                else: skipped += 1\n",
    "        else: skipped += len(files)\n",
    "    return skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6201b151-017d-4a38-bb76-9aa032fe5ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up resources...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'deep_learning_resources'...\n",
      "error: unable to create file res/data_mining/www.college.police.uk/text_cleaned/www.college.police.uk_app_mental-health_mental-vulnerability-and-illness.txt: Filename too long\n",
      "error: unable to create file res/data_mining/www.college.police.uk/text_raw/www.college.police.uk_app_mental-health_mental-vulnerability-and-illness.txt: Filename too long\n",
      "fatal: unable to checkout working tree\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete! \n"
     ]
    }
   ],
   "source": [
    "# Setup resources if needed\n",
    "setup_ran = False\n",
    "if not os.path.exists('res'):\n",
    "    print(\"Setting up resources...\")\n",
    "    setup_ran = True\n",
    "    \n",
    "    # Cleanup, clone, copy\n",
    "    repo = 'deep_learning_resources'\n",
    "    if os.path.exists(repo):\n",
    "        shutil.rmtree(repo, onerror=lambda f,p,e: os.chmod(p, stat.S_IWRITE) or f(p))\n",
    "    \n",
    "    !git clone --depth=1 https://github.com/jjv31/deep_learning_resources\n",
    "    \n",
    "    if os.path.exists(f'{repo}/res'):\n",
    "        skipped = copy_safe(f'{repo}/res', 'res')\n",
    "        print(f\"Setup complete! {'(' + str(skipped) + ' long filenames skipped)' if skipped else ''}\")\n",
    "    \n",
    "    shutil.rmtree(repo, onerror=lambda f,p,e: os.chmod(p, stat.S_IWRITE) or f(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2fb14-c59b-42a4-837c-0fbab5bf82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only refresh if we just downloaded resources\n",
    "if setup_ran:\n",
    "    from IPython.display import Javascript, display\n",
    "    import time\n",
    "    \n",
    "    print(\"Refreshing images...\")\n",
    "    \n",
    "    # Try browser refresh + aggressive image reload\n",
    "    display(Javascript(f'''\n",
    "    try {{ setTimeout(() => window.location.reload(true), 2000); }} catch(e) {{}}\n",
    "    \n",
    "    const t = {int(time.time())};\n",
    "    document.querySelectorAll('img').forEach((img, i) => {{\n",
    "        if (img.src.includes('res/')) {{\n",
    "            const src = img.src.split('?')[0];\n",
    "            setTimeout(() => img.src = src + '?v=' + t + '_' + i, i * 50);\n",
    "        }}\n",
    "    }});\n",
    "    '''))\n",
    "    \n",
    "    print(\"If images don't appear, press Ctrl+Shift+R to hard refresh!\")\n",
    "else:\n",
    "    print(\"Resources already exist, skipping setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c8642-35c9-4480-879f-009355b72a4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1 | Imports & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d861f2-77f8-401b-b33c-01954c4ad5cc",
   "metadata": {},
   "source": [
    "### 1.0 | Imports & Auxilary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdd2e9-22cb-42c6-b3db-969d7de66cd0",
   "metadata": {},
   "source": [
    "Just run these. No need to modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726a01a-d12f-4550-9f7a-d904f381413c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install artificial data generator (tabular data)\n",
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Scikit-learn libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Set plot styles\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "# Get Pandas to display all rows/columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fcce4d-4a1f-4124-bd0b-f2a0b17dd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9dd55-40eb-486c-a65e-e992c9e09cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutes Pandas' annoying future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca2739-9925-4561-908b-36759dc3dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_univariates_categorical(data):\n",
    "    data = data.astype(str) # Prevents error when sorting between strings and bools\n",
    "    numbers = data.value_counts().sort_index()\n",
    "    percentage = numbers / numbers.sum() * 100\n",
    "    percentage = percentage.round(2)\n",
    "    \n",
    "    for c, i in enumerate(numbers.index):\n",
    "        print(f\"{i}\\t\\t{numbers.iloc[c]}\\t{percentage.iloc[c]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ea3f8-cc84-4bff-a145-31bd1452e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to facilitate evaluating our models\n",
    "def print_score(clf, X, y_true):\n",
    "\n",
    "    # Gets predicted labels\n",
    "    if isinstance(clf, keras.models.Sequential): # If the model is a Keras neural network\n",
    "        y_pred = (clf.predict(X) >= 0.5).astype(int) \n",
    "    else: # Normal scikit-learn model\n",
    "        y_pred = clf.predict(X)\n",
    "\n",
    "    # Gets key performance indicators\n",
    "    accuracy = round(accuracy_score(y_true, y_pred), 4)\n",
    "    recall = round(recall_score(y_true, y_pred), 4)\n",
    "    precision = round(precision_score(y_true, y_pred), 4)\n",
    "    f1 = round(f1_score(y_true, y_pred), 4)\n",
    "\n",
    "    # Displays them\n",
    "    print(f\"F1 = {f1:.4f} | Recall = {recall* 100:.2f}% | Precision = {precision*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c224472-558c-40db-aef7-84fe0b0a4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the confusion matrix via seaborn\n",
    "def display_confusion_matrix(clf, X_test, y_true):\n",
    "\n",
    "    # Gets predicted labels\n",
    "    if isinstance(clf, keras.models.Sequential): # If the model is a Keras neural network\n",
    "        y_hat = (model.predict(X_test) >= 0.5).astype(int) \n",
    "    else: # Normal scikit-learn model\n",
    "        y_hat = clf.predict(X_test)\n",
    "        \n",
    "    mat = confusion_matrix(y_test, y_hat)\n",
    "    labels = ['No GBH', 'GBH']\n",
    " \n",
    "    sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    " \n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1a469-6563-4039-9d95-a34b6be7f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots neural network training\n",
    "def plot_performance(training_values, validation_values, metric_name = \"Recall\"):\n",
    "\n",
    "    epochs = range(1, len(training_values) + 1)\n",
    "    \n",
    "    sns.set() \n",
    "    plt.plot(epochs, training_values, '-', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, validation_values, ':', label=f'Validation {metric_name}')\n",
    "\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9e797-92e9-4a90-a958-cc89d1b66469",
   "metadata": {},
   "source": [
    "### 1.1 | Import & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"res/model_building/domestic_gbh_v2.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display frequency\n",
    "sns.countplot(x='GBH_12m', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efd947-888c-435c-b5d9-3447aaac0cb6",
   "metadata": {},
   "source": [
    "The data appear wildly imbalanced. Let's inspect more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fce323-58e3-44f8-8a7f-f0eee951f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display frequency table\n",
    "print(\"GBH in 12 months?\")\n",
    "print_univariates_categorical(df[\"GBH_12m\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c511931-8e31-4272-9e35-ab710bb7792a",
   "metadata": {},
   "source": [
    "Over 90% of individuals will not commit an act of GBH in 12 months. We'll explore this later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b3006-715d-4e0b-8cc0-8ab2d7ca4627",
   "metadata": {},
   "source": [
    "### 1.2 | Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e213b-4969-40a5-8b9d-ad42317993e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks to see if there's any NAs\n",
    "assert(df.isnull().sum().all() == 0)\n",
    "print(\"Congratulations. There are no NAs in your dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf25d0-5538-491d-a289-05c428b69ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d684e0b-7dc1-467f-adb5-a87c9a80553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode features so they can be processed by a neural network.\n",
    "# Don't worry about this. The preprocessing was handled for you.\n",
    "\n",
    "df['GBH_12m'] = df['GBH_12m'].replace(('No', 'Yes'), (0, 1))\n",
    "df['Sex'] = df['Sex'].replace(('M', 'F'), (0, 1))\n",
    "df['EthnicAppearance_cleaned'] = df['EthnicAppearance_cleaned'].replace(('Afro-Caribbean', 'Arab', 'Asian', 'Black',\n",
    "       'Chinese, Japanese or SE Asian', 'Middle Eastern',\n",
    "       'North European - White', 'South European - White', 'Unknown',\n",
    "       'White European'), (0,1,2,3,4,5,6,7,8,9))\n",
    "df['InitialRisk'] = df['InitialRisk'].replace(('H', 'S', 'M', 'Unknown'), (0, 1,2,3) )\n",
    "df['AccHowKnown'] = df['AccHowKnown'].replace(('Ex Boyfriend of victim', 'Boyfriend of victim',\n",
    "       'Husband of victim', 'Ex Girlfriend of victim',\n",
    "       'Girlfriend of victim', 'Ex Wife of victim', 'Wife of victim',\n",
    "       'Ex Husband of victim', 'Same Sex Ex intimate Partner',\n",
    "       'Ex Common Law Husband of victim', 'Common Law Husband of victim',\n",
    "       'Common Law Wife of victim', 'Civil Partner Same Sex',\n",
    "       'Ex Common Law Wife of victim', 'Same Sex Intimate Partner',\n",
    "       'Ex Civil Partner Same Sex '), (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15) )\n",
    "df['Known 1'] = df['Known 1'].replace(('Boy/Girlfriend', 'Partner/Spouse'), (0, 1))\n",
    "df['Known 2'] = df['Known 2'].replace(('Ex', 'Current'), (0, 1))\n",
    "df['ProceedingsType'] = df['ProceedingsType'].replace(('Charge/further charge', 'Second time charged', 'Adult caution',\n",
    "       'First time charged', 'Youth Conditional Caution',\n",
    "       'Third and subsequent time charged', 'Summons',\n",
    "       'Postal Charge Requisition', 'Conditional caution', 'TIC',\n",
    "       'Youth Caution'), (0,1,2,3,4,5,6,7,8,9,10))\n",
    "df['Crimes in pre 1'] = df['Crimes in pre 1'].replace(('No', 'Yes'), (0, 1))\n",
    "df['DV in Pre 1'] = df['DV in Pre 1'].replace(('No', 'Yes'), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1194f76-4b69-4cf5-9c67-21dbb967d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode numberic columns\n",
    "df['Age'] = pd.to_numeric(df['Age'],downcast=\"float\")\n",
    "df['Crimes in pre'] = pd.to_numeric(df['Age'],downcast=\"float\")\n",
    "df['DV in Pre'] = pd.to_numeric(df['Age'],downcast=\"float\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the columns more intuitive\n",
    "df.rename(columns={\"Sex\": 'Offender_isMale',\n",
    "                  \"EthnicAppearance_cleaned\" : \"Offender_ethnicAppearance\",\n",
    "                  \"Age\" : \"Offender_Age\",\n",
    "                  \"Crimes in pre\" : \"Previous_Crimes\",\n",
    "                  \"DV in Pre\" : \"Previous_DV\",\n",
    "                  \"InitialRisk\" : \"DASH_Assessment\",}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ba42e-604a-4da1-9c47-69b47b563857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops each person's ID\n",
    "df.drop([\"ID\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a37fdb-48a2-4546-a278-c684c8663da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays preprocessed dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11fc0b-7464-4d77-8ad2-5787d009ea65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2 | Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4409eb-b1ff-42a6-9a09-73d72d45ffc2",
   "metadata": {},
   "source": [
    "### 2.0 | Section Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b9335-fc7c-4bec-a8f5-9a95d2eca71c",
   "metadata": {},
   "source": [
    "We'll need to split our dataset into a (i) training set and (ii) a testing set. For both the training and testing set, we'll need to split the features (X) from the label (y). We'll do that in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5439a-e4ab-4694-9432-e32afb43ce38",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/model_building/data_split_illustration.jpg\" width=\"50%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f2478-c119-44af-99e0-b3b96365c862",
   "metadata": {},
   "source": [
    "### 2.1 | Split Dataset into Features (X) and Label (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the output (y) from the inputs (X). The output is what we're hoping to predict.\n",
    "# In machine learning lingo, the input variable should be named X (capital x) and the output variable should be named y (lowercase y)\n",
    "X = df.drop(['GBH_12m'], axis=1)\n",
    "y = df['GBH_12m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays first rows of features. Confirms (a) they do not contain the label and (b) they look OK\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33732a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays first 3 outputs. Confirms we only have the label (i.e. whether an individual will commit GH)\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's examine the sizes of the training and testing sets\n",
    "print(f\"Training set size = {y_train.size}\\nTesting set size = {y_test.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6af94-5dc5-4858-a1ab-60246bfbd755",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3 | Artificially Generate Future GBH via SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242a799-095f-404f-8cc4-f897035cd03a",
   "metadata": {},
   "source": [
    "### 3.1 | Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7acba-8217-4b9d-9fda-b10274a4d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, Let's have a look at the labels again. \n",
    "# We'll only look at the training set because that's the dataset that the model is training on --- the same dataset that is causing the model to behave poorly.\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc15b59-d925-44e9-b9c5-bbd4378e0da0",
   "metadata": {},
   "source": [
    "Our training dataset is wildly unbalanced. This lack of balance is very dangerous for machine learning because models learn that, if they ignore the minority case, they can achieve a very high accuracy score. \n",
    "\n",
    "Let's fix that via SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88129be9-4432-43f8-850b-3f1bd28a67f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 | Artificial Data Generation via SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440cbc55-0fb2-4bb7-9b5f-7127d863ccd2",
   "metadata": {},
   "source": [
    "Note that we only apply SMOTE to the testing set. We don't want to affect the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e08be4-d8a9-4502-9580-c8c1e7172235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SMOTE to the training set.\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    \n",
    "    smote_resampler = SMOTE()\n",
    "    X_train, y_train = smote_resampler.fit_resample(X_train, y_train)\n",
    "    print(\"SMOTE ran successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Caution - you do not have SMOTE installed. Perhaps you're running an incompatible Python version?\")\n",
    "    print(f\"Error = {e}\")\n",
    "\n",
    "    print(\"Not to worry. We will use dataset backups that have undergone SMOTE\")\n",
    "    X_train = pd.read_csv(\"res/model_building/X_train_SMOTE_backup.csv\")\n",
    "    y_train = pd.read_csv(\"res/model_building/y_train_SMOTE_backup.csv\")\n",
    "\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172d978-5b5c-41de-bbf4-72edfa584a67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 | Synthetic vs. Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c291d-7718-4db9-b1b7-b5abd167d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the real data to the synthetic ones\n",
    "\n",
    "print(\"REAL DATA\")\n",
    "print(\"GBH Label (1 = will commit GBH in 12 months):\")\n",
    "print(y_train[:2000].head(5) )\n",
    "\n",
    "print(\"Features:\")\n",
    "X_train[:2000].head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6882325-2720-462e-ae5c-0e4adca89e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SYNTHETIC DATA\")\n",
    "print(\"GBH Label (1 = will commit GBH in 12 months):\")\n",
    "print(y_train[2000:].head(5) )\n",
    "\n",
    "print(\"Features:\")\n",
    "X_train[2000:].head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368d5300-510e-4ce8-a506-3e7c6377b520",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4 | Fit & Optimize Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abccb7f-d043-46d5-87ad-d0bd026d493a",
   "metadata": {},
   "source": [
    "### 4.1 | Creates basic Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878c485-a23c-486f-b70e-5fb13cdbc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fits a decision tree via three lines of code\n",
    "original_random_forest = RandomForestClassifier(random_state=42)\n",
    "original_random_forest.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a7d95-7976-471e-9a57-90f7e9125949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Results\")\n",
    "print_score(original_random_forest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7ae64-61c5-4d1e-9005-d43fc482f7c4",
   "metadata": {},
   "source": [
    "### 4.2 | Optimize Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901923d-086f-458a-96fe-8a9b3cb7f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperparams = {\n",
    "    'class_weight' : [\"balanced\", \"balanced_subsample\"],\n",
    "    'criterion' : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'n_estimators': [10, 50, 100,],\n",
    "    'max_depth': [2, 4, 6, None],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 50, 200],\n",
    "}\n",
    "\n",
    "\n",
    "# Init the random search\n",
    "rf_cv = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=rf_hyperparams,\n",
    "                           n_iter=100, # NOTE - We're only doing 100 searches for the sake of time. We won't find the optimal combination\n",
    "                           cv=2, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Runs the search\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72970289-fad6-41e3-b320-f653a96c7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refits model with optimal hyperparameters\n",
    "optimized_random_forest = RandomForestClassifier(**rf_best_params)\n",
    "optimized_random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1cf9d-b5e2-441b-8646-468c949eb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRank #2: Original Random Forest\")\n",
    "print_score(original_random_forest, X_test, y_test)\n",
    "\n",
    "print(\"\\nOptimized Results\")\n",
    "print_score(optimized_random_forest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82e803-c7ed-42db-a1aa-7c270015fbf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5 | Create Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3753412-1f12-40f9-9329-3eefd81217b7",
   "metadata": {},
   "source": [
    "### 5.0 | Section Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae68bf1-20c4-488b-8b93-527a0b037785",
   "metadata": {},
   "source": [
    "Our initial neural network can be visualized via the below diagram. First we'll compile it (§5.1), then we'll train it (§5.2), evaluate it's training (§5.3) before getting its ultimate performance (§5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7c759-1cac-4c65-844b-4528ddc79fcb",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/model_building/gbh_nn_diagram.jpg\" width=\"50%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf3ef3-0b4c-44e8-85bf-284d2088d092",
   "metadata": {},
   "source": [
    "### 5.1 | Constructs Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb4e71-2b0e-4c07-9d00-41ccea91e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = X.shape[1]\n",
    "print(f\"There are {number_of_features} to be inputted into the neural network. Thus, there should be {number_of_features} input nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ed4a0-3b36-46e0-9ec4-dabb2e0fbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network\n",
    "model = Sequential() \n",
    "model.add( Input( shape= (number_of_features,) ) ) \n",
    "model.add(Dense(16, activation='relu', ))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compiles & Summarizes model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=.0001), \n",
    "              metrics=[keras.metrics.Precision(name=\"precision\"), keras.metrics.Recall(name=\"recall\"), ]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca555b-d0b0-42d7-9ab1-283b4ad7e0b2",
   "metadata": {},
   "source": [
    "### 5.2 | Trains Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1eb74-ebfb-4196-9b09-2ccffb3f8401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trains the model.\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62d2ee9-b8c9-4cf3-8510-b8b9d90b6608",
   "metadata": {},
   "source": [
    "### 5.3 | Evaluates Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90e198-a1c2-4faf-bf56-bd73f714f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, val_loss = hist.history[\"loss\"], hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f060f-a09f-45c6-8bac-fa8b54247859",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, val_prec = hist.history[\"precision\"], hist.history[\"val_precision\"]\n",
    "plot_performance(prec, val_prec, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc0a64-acc5-44ec-ae37-773555b4de45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall, val_recall = hist.history[\"recall\"], hist.history[\"val_recall\"]\n",
    "plot_performance(recall, val_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369cd32-2ac9-4bf1-a421-acf9e9d1408f",
   "metadata": {},
   "source": [
    "### 5.4 | Evaluates Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265dd3e-9c23-42d4-9155-6f96624e9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ca254-8a21-43c9-aed3-5ecbc13175c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52abbe9-6c35-459e-abaa-3cabe64e8ae2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6 | Improve the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377541f-a2b8-4059-a625-51c3ff65f238",
   "metadata": {},
   "source": [
    "### 6.0 | Section Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12487b-8264-4e67-a8cb-bf02728479ab",
   "metadata": {},
   "source": [
    "This section follows the same logic as the previous, except your task is to improve the ultimate performance of the neural network. This can involve any of the following:\n",
    "\n",
    "<ul>\n",
    "  <li> Add or remove more neurons to the hidden layer. </li>\n",
    "  <li> Add more hidden layer(s). </li>\n",
    "  <li> Adjust the activation function. </li>\n",
    "  <li> Adjust the learning rate. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a3d42-002b-4b4b-addb-72bb4617e5d3",
   "metadata": {},
   "source": [
    "### 6.1 | Compile Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d93ce-b8c9-40d3-a464-e4f700f35441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network. ADJUST THIS CODE so your neural network improves upon the existing one.\n",
    "your_neural_network = Sequential() \n",
    "your_neural_network.add( Input( shape= (number_of_features,) ) ) \n",
    "your_neural_network.add(Dense(16, activation='relu', ))\n",
    "your_neural_network.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compiles & Summarizes model\n",
    "your_neural_network.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=.0001), \n",
    "              metrics=[keras.metrics.Precision(name=\"precision\"), keras.metrics.Recall(name=\"recall\"), ]) \n",
    "your_neural_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13041a0-2f2c-4e94-b991-02fd22c9193e",
   "metadata": {},
   "source": [
    "### 6.2 | Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618da7f-3615-4bef-8d77-3442f7fabaae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trains the model.\n",
    "your_hist = your_neural_network.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78986946-5641-4146-88ab-bff69c3d36c5",
   "metadata": {},
   "source": [
    "### 6.3 | Evaluate Your Neural Network's Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103d48f-dab2-43d6-92f5-a90cf3fffbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots loss\n",
    "loss, val_loss = your_hist.history[\"loss\"], your_hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b476afb-df22-4eba-8442-63f0e2c33842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "prec, val_prec = your_hist.history[\"precision\"], your_hist.history[\"val_precision\"]\n",
    "plot_performance(prec, val_prec, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fc4c4-f214-4cf2-806e-b1a9aa49c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, val_recall = your_hist.history[\"recall\"], your_hist.history[\"val_recall\"]\n",
    "plot_performance(recall, val_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12242480-42c5-4075-9ba2-52c3ad05c82f",
   "metadata": {},
   "source": [
    "### 6.4 | Evaluates Your Neural Network on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dbf01-3ece-401f-bce5-2279b7c42afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(your_neural_network, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ae162-2099-4539-9b05-b8ae0995d2f3",
   "metadata": {},
   "source": [
    "Does your f1 score exceed the previous neural network's f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6182f4-dc9b-4f48-9b60-a33895ecdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(your_neural_network, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce8971-c36b-4e7f-81a1-7760671dde1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
