{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eddaf3f-5883-4066-b162-5bffa820959e",
   "metadata": {},
   "source": [
    "# Forecasting Taxi Fare via Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163ec86-7a68-4574-b0ac-4ee9bb1a0108",
   "metadata": {},
   "source": [
    "\n",
    "Imagine that you work for a taxi company, and that one of your customers' biggest complaints is that they don't know how much a ride will cost until it's over. That's because distance is just one of several factors from which taxi fares are calculated. You decide to do something about it by building a mobile app that customers can use when they climb into a taxi to estimate what the fare will be. To provide the smarts for the app, you intend to use the massive amounts of fare data the company has collected over the years to train a neural network. Let's use a portion of a larger taxi-fare dataset from New York City to train the network to predict a fare amount given the time of day, the pickup and dropoff locations, and other information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ee929-63e7-48b4-937f-33375a3b3c7c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/regression/taxi_icon.jpg\" width=\"25%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bce647-cb8c-47ca-a9b9-cc90f5174a31",
   "metadata": {},
   "source": [
    "In the process, you'll see <strong> that neural networks can also be used for regression in addition to classification</strong>, which represents the primary learning goal of this practicum. This is accomplished by using a linear activation function for the output layer rather than a sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea74da0-d651-4702-9f48-fc02a81907b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0 | Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc956f7-9828-4c0c-8f87-334322d1aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09702caa-95e9-42c7-949b-4089148cc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_safe(src, dst, max_len=200):\n",
    "    \"\"\"Copy files, skip long paths\"\"\"\n",
    "    skipped = 0\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        rel_path = os.path.relpath(root, src)\n",
    "        dst_root = os.path.join(dst, rel_path) if rel_path != '.' else dst\n",
    "        if len(dst_root) < max_len:\n",
    "            os.makedirs(dst_root, exist_ok=True)\n",
    "            for file in files:\n",
    "                dst_file = os.path.join(dst_root, file)\n",
    "                if len(dst_file) < max_len:\n",
    "                    try: shutil.copy2(os.path.join(root, file), dst_file)\n",
    "                    except: skipped += 1\n",
    "                else: skipped += 1\n",
    "        else: skipped += len(files)\n",
    "    return skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aef91b4-4576-4b9d-ad96-5f6f1e7965b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup resources if needed\n",
    "setup_ran = False\n",
    "if not os.path.exists('res'):\n",
    "    print(\"Setting up resources...\")\n",
    "    setup_ran = True\n",
    "    \n",
    "    # Cleanup, clone, copy\n",
    "    repo = 'deep_learning_resources'\n",
    "    if os.path.exists(repo):\n",
    "        shutil.rmtree(repo, onerror=lambda f,p,e: os.chmod(p, stat.S_IWRITE) or f(p))\n",
    "    \n",
    "    !git clone --depth=1 https://github.com/jjv31/deep_learning_resources\n",
    "    \n",
    "    if os.path.exists(f'{repo}/res'):\n",
    "        skipped = copy_safe(f'{repo}/res', 'res')\n",
    "        print(f\"Setup complete! {'(' + str(skipped) + ' long filenames skipped)' if skipped else ''}\")\n",
    "    \n",
    "    shutil.rmtree(repo, onerror=lambda f,p,e: os.chmod(p, stat.S_IWRITE) or f(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a673d1f-b5f9-4c11-bb58-6337c2662077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources already exist, skipping setup.\n"
     ]
    }
   ],
   "source": [
    "# Only refresh if we just downloaded resources\n",
    "if setup_ran:\n",
    "    from IPython.display import Javascript, display\n",
    "    import time\n",
    "    \n",
    "    print(\"Refreshing images...\")\n",
    "    \n",
    "    # Try browser refresh + aggressive image reload\n",
    "    display(Javascript(f'''\n",
    "    try {{ setTimeout(() => window.location.reload(true), 2000); }} catch(e) {{}}\n",
    "    \n",
    "    const t = {int(time.time())};\n",
    "    document.querySelectorAll('img').forEach((img, i) => {{\n",
    "        if (img.src.includes('res/')) {{\n",
    "            const src = img.src.split('?')[0];\n",
    "            setTimeout(() => img.src = src + '?v=' + t + '_' + i, i * 50);\n",
    "        }}\n",
    "    }});\n",
    "    '''))\n",
    "    \n",
    "    print(\"If images don't appear, press Ctrl+Shift+R to hard refresh!\")\n",
    "else:\n",
    "    print(\"Resources already exist, skipping setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba9ada-7daa-4ad0-84c0-ece5c82431ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1 | Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132cf3a5-32fd-4465-af8d-1bb46390de19",
   "metadata": {},
   "source": [
    "### 1.1 | Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3fe60-372c-426b-830d-a03b4395750b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tqdm datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54af1c-8a38-43e0-b52a-a00c37918008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Neural network\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Other\n",
    "import datetime\n",
    "from math import sqrt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547b8a3-0da3-4ffb-8757-27741cf2fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_univariates_metric(data, nameToPrint=None):\n",
    "\n",
    "    # Mode - Handling multimodal cases\n",
    "    mode_result = data.mode()\n",
    "    if len(mode_result) == 0:  # No mode found\n",
    "        mode_result = None\n",
    "    else:\n",
    "        mode_result = mode_result[0]\n",
    "\n",
    "    # Print output\n",
    "    print(f\"Descriptives for {nameToPrint}\")\n",
    "    print(f\"Mean = {round(data.mean(),2)} | Median = {round(data.median(),2)} | Mode = {mode_result} | \"\n",
    "          f\"Min = {data.min()} | Max = {data.max()} | SD = {round(data.std(),2)} | \"\n",
    "          f\"IQR(25) = {data.quantile(0.25)} | IQR(75) = {data.quantile(0.75)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fe9a7-1ffb-4937-9a41-e836283b6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the performance of the neural network\n",
    "def plot_performance(training_values, validation_values, metric_name = \"Recall\"):\n",
    "\n",
    "    epochs = range(1, len(training_values) + 1)\n",
    "    \n",
    "    sns.set() \n",
    "    plt.plot(epochs, training_values, '-', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, validation_values, ':', label=f'Validation {metric_name}')\n",
    "\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5add96-01cf-4e2e-b207-05eddc372947",
   "metadata": {},
   "source": [
    "### 1.2 | Loads & Explores Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f55313-e819-41bc-b393-e0f277da591c",
   "metadata": {},
   "source": [
    "Start by loading the dataset and shaping it so that it's suitable for use in machine learning. The data requires a fair amount of prep work before it's of any use at all â€” something that is not uncommon in machine learning. Data scientists often find that collecting and preparing data accounts for 90% or more of their time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742700d-e62a-4ae7-ac9e-94e8256bd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('res/regression/taxi-fares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3579069-1320-4c33-ba53-ba414e88d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns does the dataset contain?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0d222-be62-4eb3-a956-519055a30264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are any of the columns missing values?\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1d68e-06ba-48ea-b627-47b3d00a0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['passenger_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c563960-2454-4b84-9a5e-4f31da933396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the rows in the dataset have a passenger count of 1. \n",
    "# Let's just focus on fares with one passenger.\n",
    "\n",
    "df = df[df['passenger_count'] == 1]\n",
    "df = df.drop(['key', 'passenger_count'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab915a-858c-47ea-9cba-4171a1e3af8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2 | Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c292b8e-cb5f-48c2-9a3f-777c80567d9c",
   "metadata": {},
   "source": [
    "### 2.1 | Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82a1b9-7722-4ef1-813b-66a5257044dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff00f06-a469-475f-ac51-b1976ca5ba87",
   "metadata": {},
   "source": [
    "These features are terrible for creating a neural network.\n",
    "\n",
    "First, neural networks cannot process a datetime, so we need to turn that into meaningful ordinal features. In this case, we are going to create an ordinal feature that flags the day of the week the ride took place, as well as one that specifies the hour they were picked up, as both likely affect fare prices. For example, getting picked up at 5 PM on a weekday will likely incur a different fare than being picked up at 11 PM on a Sunday!\n",
    "\n",
    "Second, longitude and latitude are large numbers that may confound a neural network, and they're not inherently meaningful on their own. Thus, we're going to extract distance from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec04ff5-b3d9-42a3-a0f9-129b7d8c6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loops through each row of the dataset\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "    # From pickup_datetime, turn it into something meaningful. That is, extract day_of_week and pickup_time from it.\n",
    "    dt = datetime.datetime.strptime(row['pickup_datetime'], '%Y-%m-%d %H:%M:%S UTC')\n",
    "    df.at[i, 'day_of_week'] = dt.weekday()\n",
    "    df.at[i, 'pickup_time'] = dt.hour\n",
    "\n",
    "    # Calculates distance\n",
    "    x = (row['dropoff_longitude'] - row['pickup_longitude']) * 54.6 # 1 degree = 54.6 miles\n",
    "    y = (row['dropoff_latitude'] - row['pickup_latitude']) * 69.0   # 1 degree = 69 miles\n",
    "    distance = sqrt(x**2 + y**2)\n",
    "    df.at[i, 'distance'] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da65bd1-7290-4a6e-a242-7af6ec98760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the now irrelevant columns\n",
    "df = df.drop(columns=['pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'] )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c2c9e-67b9-4bdb-b9a0-d4b8e011bf9a",
   "metadata": {},
   "source": [
    "### 2.2 | Check for anomalous valus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d242105-0224-4f1f-a8c2-a411a620c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect fare amount\n",
    "print_univariates_metric(df[\"fare_amount\"], \"Fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7356bd-2a14-4c37-a6bf-104fe60ef3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are negative fares, which doesn't make sense. Let's remove them.\n",
    "# Let's also remove really extreme fares, or fares that are roughly 2 SDs above the mean (i.e., 11.21 + 9.7 * 2).\n",
    "\n",
    "df = df[(df['fare_amount'] > 0.0) & df['fare_amount'] < 30.61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e142ca-1730-4eaf-96bc-1c3ac064acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect distances.\n",
    "print_univariates_metric(df[\"distance\"], \"Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48e775-368a-46bd-a195-0ed2b9ceacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yikes! There are so many outliers that it's massively inflating the mean and SD. Let's remove them\n",
    "# IQR (75) is 2.4. Let's limit the distance to 10 miles and make the minimum distance 1 mile\n",
    "df = df[(df['distance'] > 1.0) & (df['distance'] < 10.0)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437725e9-4982-43cf-8bd9-8213bf239ecf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3 | Trains Initial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6af73f-60fc-4753-b169-e3b8cfdfe4de",
   "metadata": {},
   "source": [
    "Now it's time build a neural network and train it with the data prepared in the previous exercise. We'll create two hidden layers with 512 neurons each and an input layer that accepts three values: distance, the day of the week, and the time of day. Since the model is designed to predict a fare amount, the output layer will have one neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a428fa3-8da7-42f2-a402-cb1da7adbcb2",
   "metadata": {},
   "source": [
    "### 3.1 | Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6a30b-aec4-43d7-b37c-73fef64936c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=[\"fare_amount\"]), df[\"fare_amount\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Size of training set = {X_train.shape[0]} fares\")\n",
    "print(f\"Size of test set = {X_test.shape[0]} fares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d77603-bfa7-4464-bd93-883d6c6b05f1",
   "metadata": {},
   "source": [
    "### 3.2 | Compile & Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033de181-8ce0-4219-9e2a-b2b3d665c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( Input( shape=(3,) ) )  # Input layer\n",
    "model.add(Dense(512, activation='relu',))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=.001), loss='mse', metrics=[metrics.MeanSquaredError(name='mse')] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a7da6-dd7d-46e6-8e99-e501b4e566d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                 epochs=100, batch_size=1028)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866749f-d676-4536-a236-e7d7531b1399",
   "metadata": {},
   "source": [
    "### 3.3 | Evaluate Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31aa897-6b89-4f1f-89d8-cc3f90be2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(hist.history[\"loss\"], hist.history[\"val_loss\"], metric_name = \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0c0c9-cf71-49c9-9599-118db02af910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to assess how well a model performs is the r2 score.\n",
    "# Uses R2 to determine how good the model was on the training and testing set.\n",
    "\n",
    "print(\"R2 score for training set\")\n",
    "print( r2_score(y_train, model.predict(X_train)) )\n",
    "\n",
    "print(\"R2 score for testing set\")\n",
    "print( r2_score(y_test, model.predict(X_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dcd39d-2eaa-4fcc-a7ed-6cd39dc8c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to evaluate our model is to assess how 'off' our predicted fare values were from our true values. \n",
    "# We'll evaluate this through median & IQR to avoid outliers\n",
    "\n",
    "prediction_error = model.predict(X_test)[0] - y_test\n",
    "IQR25, median, IQR75 = round(prediction_error.quantile(0.25), 2), round(prediction_error.quantile(0.5), 2), round(prediction_error.quantile(0.75), 2)\n",
    "print(f\"Your fare estimation is usually ${median} off. 50% of the time, your fare is between ${IQR25} and ${IQR75} off.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5ba29-4df9-4c88-99e6-7b4e99b48bc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4 | Forecasting Fares through Our Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7f00b-5c1e-4bdc-9ca3-120f1146e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate what it will cost to hire a taxi for a 2-mile trip at 5:00 p.m. on Friday afternoon.\n",
    "predicted_fare = model.predict(np.array([[4, 17, 2.0]]))[0][0]\n",
    "print(f\"Estimated fare = ${predicted_fare}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a1518-0f30-404a-a2f0-c14af41c6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now predict the fare amount for a 2-mile trip taken at 5:00 p.m. one day later (on Saturday).\n",
    "predicted_fare = model.predict(np.array([[0, 10, 5.0]]))[0][0]\n",
    "print(f\"Estimated fare = ${predicted_fare}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6ef41-dd6c-4d9e-b290-00724a88a5ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5 | Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ab581-fb32-4476-a0b8-b532c1f595c1",
   "metadata": {},
   "source": [
    "### 5.0 | Section Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0a204-3fc3-455d-8c9d-6ab07722555e",
   "metadata": {},
   "source": [
    "Your task is to improve the neural network so it can better predict fares relative to the original model. Namely, the original model appears in Â§3.1. Your task is to modify it such that it achieves a better r2 score on the testing set relative to the original model (Â§3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9bb5f5-fc90-4a07-a05b-694e2447453e",
   "metadata": {},
   "source": [
    "### 5.1 | Compile & Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5eb21b-70a5-465d-a58c-2d44e35e6247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# *****************************************\n",
    "# EXERCISE\n",
    "# *****************************************\n",
    "\n",
    "# The code for the original model appears below.\n",
    "# Modify that code so the model performs better.\n",
    "\n",
    "your_model = Sequential()\n",
    "your_model.add( Input( shape=(3,) ) ) \n",
    "your_model.add(Dense(512, activation='relu',))\n",
    "your_model.add(Dense(512, activation='relu'))\n",
    "your_model.add(Dense(1))\n",
    "\n",
    "your_model.compile(optimizer=Adam(learning_rate=.001), loss='mse', metrics=[metrics.MeanSquaredError(name='mse')] )\n",
    "your_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91a320-aaeb-4b11-a894-f33a614c3b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "your_hist = your_model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                 epochs=100, batch_size=1028)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccf9f1-ce81-4ed2-91b2-c6c35e824e86",
   "metadata": {},
   "source": [
    "### 5.2 | Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ffa1b6-7c1d-4236-ade6-138a51b36187",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(your_hist.history[\"loss\"], your_hist.history[\"val_loss\"], metric_name = \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92436586-8f18-41a8-bc27-8751f524ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to determine if your model out/underperformed the original model.\n",
    "\n",
    "print(\"R2 score for training set\")\n",
    "print( r2_score(y_train, your_model.predict(X_train)) )\n",
    "\n",
    "print(\"R2 score for testing set\")\n",
    "print( r2_score(y_test, your_model.predict(X_test)) )\n",
    "\n",
    "print(\"Did your model outperform the original model? Let's compare r2 scores on the testing set.\")\n",
    "print(f\"Original r2 score = {r2_score(y_test, model.predict(X_test))} | Your r2 score = {r2_score(y_test, your_model.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8adb2b-154d-44a8-bb37-5e63c908a508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
