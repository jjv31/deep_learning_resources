{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a090555-a6c0-425e-9da0-09cb5b908826",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs) & Its Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237e13f-df61-4c18-8069-4c2e48725a69",
   "metadata": {},
   "source": [
    "You'll be using a popular benchmark dataset - Fashion-MNIST - in order to create, train, and evaluate a convolutional neural network whose Alexnet diagram appears below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe34f4-345f-4919-a8db-a658783f3fc4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/cnn_fashion/alexnet_initial_cnn.jpg\" width=\"80%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b609524f-ffb6-4de8-8bdc-273dbe6dd22c",
   "metadata": {},
   "source": [
    "After you create this CNN, you'll then make a variety of modifications to it in order to better understand CNN hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d3420-5acb-43a3-8f82-39a173072fc5",
   "metadata": {},
   "source": [
    "### The Fashion-MNIST Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d53b07-8c1b-419e-84ee-df2c67ed59b1",
   "metadata": {},
   "source": [
    "Before you go ahead and load in the data, it's good to take a look at what you'll exactly be working with! The Fashion-MNIST dataset is a dataset of Zalando's article images, with 28x28 grayscale images of 70,000 fashion products from 10 categories, and 7,000 images per category. \n",
    "\n",
    "Fashion-MNIST is similar to the MNIST dataset that you might already know, which you use to classify handwritten digits. That means that the image dimensions, training and test splits are similar to the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eac1ae-0c78-4fdc-93e4-907e588d151e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/cnn_fashion/dataset_cover.png\" width=\"30%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bc8fa-d092-471b-9942-2a0cd9b257f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0 | Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bfc5a-83d1-4369-9d3e-1c946881b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c98b9-55a7-40fb-a521-6f12c4f9a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_safe(src, dst, max_len=200):\n",
    "    \"\"\"Copy files, skip long paths\"\"\"\n",
    "    skipped = 0\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        rel_path = os.path.relpath(root, src)\n",
    "        dst_root = os.path.join(dst, rel_path) if rel_path != '.' else dst\n",
    "        if len(dst_root) < max_len:\n",
    "            os.makedirs(dst_root, exist_ok=True)\n",
    "            for file in files:\n",
    "                dst_file = os.path.join(dst_root, file)\n",
    "                if len(dst_file) < max_len:\n",
    "                    try: shutil.copy2(os.path.join(root, file), dst_file)\n",
    "                    except: skipped += 1\n",
    "                else: skipped += 1\n",
    "        else: skipped += len(files)\n",
    "    return skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e483c77-3d00-480e-ab26-dff23aba0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup resources if needed\n",
    "setup_ran = False\n",
    "if not os.path.exists('res'):\n",
    "    print(\"Setting up resources...\")\n",
    "    setup_ran = True\n",
    "    \n",
    "    # Cleanup, clone, copy\n",
    "    repo = 'deep_learning_resources'\n",
    "    if os.path.exists(repo):\n",
    "        shutil.rmtree(repo, onerror=lambda f,p,e: os.chmod(p, stat.S_IWRITE) or f(p))\n",
    "    \n",
    "    !git clone --depth=1 https://github.com/jjv31/deep_learning_resources\n",
    "    \n",
    "    if os.path.exists(f'{repo}/res'):\n",
    "        skipped = copy_safe(f'{repo}/res', 'res')\n",
    "        print(f\"Setup complete! {'(' + str(skipped) + ' long filenames skipped)' if skipped else ''}\")\n",
    "    \n",
    "    shutil.rmtree(repo, onerror=lambda f,p,e: os.chmod(p, stat.S_IWRITE) or f(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50560de6-8965-46ed-99fa-0e0e36a1f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only refresh if we just downloaded resources\n",
    "if setup_ran:\n",
    "    from IPython.display import Javascript, display\n",
    "    import time\n",
    "    \n",
    "    print(\"Refreshing images...\")\n",
    "    \n",
    "    # Try browser refresh + aggressive image reload\n",
    "    display(Javascript(f'''\n",
    "    try {{ setTimeout(() => window.location.reload(true), 2000); }} catch(e) {{}}\n",
    "    \n",
    "    const t = {int(time.time())};\n",
    "    document.querySelectorAll('img').forEach((img, i) => {{\n",
    "        if (img.src.includes('res/')) {{\n",
    "            const src = img.src.split('?')[0];\n",
    "            setTimeout(() => img.src = src + '?v=' + t + '_' + i, i * 50);\n",
    "        }}\n",
    "    }});\n",
    "    '''))\n",
    "    \n",
    "    print(\"If images don't appear, press Ctrl+Shift+R to hard refresh!\")\n",
    "else:\n",
    "    print(\"Resources already exist, skipping setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b66e8-7cc1-4a3f-b167-1c62a9f9ba17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1 | Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9147330-3321-4c61-bb28-849db5d8a4ff",
   "metadata": {},
   "source": [
    "### 1.1 | Imports and Auxilary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba005e-9f03-48e9-a7a5-020068cddffb",
   "metadata": {},
   "source": [
    "Just run these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0343b-65b5-4588-a344-759c55e40e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets & Math\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical # One Hot Encoding\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cb4db-655a-45a9-96f9-03fda0e61e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks\n",
    "from keras.datasets import fashion_mnist\n",
    "import keras as keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79e6d7-c6aa-486d-aaca-9bf83c060991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the performance of the neural network\n",
    "def plot_performance(training_values, validation_values, metric_name = \"Recall\"):\n",
    "\n",
    "    epochs = range(1, len(training_values) + 1)\n",
    "    \n",
    "    sns.set() \n",
    "    plt.plot(epochs, training_values, '-', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, validation_values, ':', label=f'Validation {metric_name}')\n",
    "\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e03db-7029-4f33-bc97-c57245bdf6bb",
   "metadata": {},
   "source": [
    "### 1.2 | Loads Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6586d1-16e4-4851-ac52-d2822eb60236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be loading the dataset directly from KERAS, and they have already seperated it into a trianing & testing split.\n",
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe6455-f267-4176-ba0e-57a60b16c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that these are NOT pandas datasets: they're numpy arrays\n",
    "# Thus, we can't use .head() and other Pandas functions.\n",
    "type(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120f13f-c1ae-45ef-94f8-41502e5a797b",
   "metadata": {},
   "source": [
    "### 1.3 | Inspect Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdd34e-bc0e-4a36-98b4-77ea8add9bbe",
   "metadata": {},
   "source": [
    "Let's now analyze how images in the dataset look like. Even though you know the dimension of the images by now, it's still worth the effort to analyze it programmatically. For example, you might have to rescale the image pixels and resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a8216-a252-495c-8be2-a7bb281d7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape : ', train_X.shape, train_Y.shape) # 60,000 images that are 28 x 28\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape) # 10,000 images that are 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad2658-0bf5-4dbd-b555-84e7f8aa1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_Y)\n",
    "\n",
    "print('Total number of outputs : ', len(classes))\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84df0f1-5ce7-43e3-8d25-23c86f7de9da",
   "metadata": {},
   "source": [
    "### 1.4 | Visualize Dataset Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42e88a-a8b7-4231-850a-123fd86d0702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can't visualize these contents normally because they're images.\n",
    "# Here is how our datast is stored: train_X[image_number, row_number, col_number]\n",
    "# image_number - the first index of our array. It refers to the image number in our dataset\n",
    "# row_number - the second index refers to the row of the image\n",
    "# col_number - the second index refers tot he column number\n",
    "\n",
    "# Thus, each image in the dataset is a 28 x 28 array with a brightness value between 0 (black) and 255 (white). \n",
    "\n",
    "# Let's inspect the first image\n",
    "train_X[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580d13d-52f7-442d-9fdd-08c1d01128a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of viewing the raw image data, let's render the image via MatPlotLib\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121) # For displaying the graphs nicely. refers to rows_in_subplot, cols_in_subplot, position_of_current_graph.\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(f\"Ground Truth : {train_Y[0]}\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(f\"Ground Truth : {test_Y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca14222-d409-492f-a3c4-6d05ad943fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************\n",
    "# EXERCISE\n",
    "# ******************************\n",
    "# Do the same thing except display the 5th image in our training & testing set.\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Training\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(f\"Ground Truth : {train_Y[0]}\")\n",
    "\n",
    "# Testing\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(f\"Ground Truth : {test_Y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51aed8-b599-423d-99eb-87bf9e989710",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2 | Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8debca1d-16bc-453e-b879-d2deff05bbc2",
   "metadata": {},
   "source": [
    "\n",
    "As you could see in the above plot, the images are grayscale images have pixel values that range from 0 to 255. Also, these images have a dimension of 28 x 28. As a result, you'll need to preprocess the data before you feed it into the model.\r\n",
    "\r\n",
    "As a first step, convert each 28 x 28 image of the train and test set into a matrix of size 28 x 28 x 1 which is fed into the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d42565-af2a-4726-a3fe-0249009be3ca",
   "metadata": {},
   "source": [
    "### 2.1 | Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184fbc5-4d30-4037-950f-b4f450790d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brightness values of our image range from 0 to 255\n",
    "# However, neural networks are best suited for handling values with a smaller rnage, like 0-1.\n",
    "# Thus, we'll convert these values to a 0-1 decimal.\n",
    "\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef78383-bf07-4cae-9261-daf1a059609d",
   "metadata": {},
   "source": [
    "### 2.2 | One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61ccbc-54bf-4b6c-9bc9-2ef9cb11a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a mutliclass classification problem with 10 classes.\n",
    "# Thus, we'll need 10 output neurons: 1 neuron per class.\n",
    "# To make our datset compatible with our neural network, the class needs to be one-hot encoded.\n",
    "\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ed201-c39b-4379-b480-bd74ed3291f3",
   "metadata": {},
   "source": [
    "### 2.3 | Create Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b74eeb-20c2-4a12-b35e-38ca73b2b29f",
   "metadata": {},
   "source": [
    "We have a lot of data in this dataset. We have so much data that we'll do the \"proper\" thing of evaluating our neural network's training via a validation set rather than the testing set. This helps ensure that the testing set represents an unbiased view of the model's performance in the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eba63-c64e-4d04-b977-3fdc1ef4d2ab",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <img src = \"res/cnn_fashion/dataset_split.jpg\" width=\"30%\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41b3d9-b749-4963-a2d3-ce5b87b25d1d",
   "metadata": {},
   "source": [
    "Note that we'll be creating our validation set using 10% of the training set (c.f., 10% of the whole dataset!). Thus, the numbers on the diagram aren't exactly right, but the underlying concept is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3061b88-5a21-4799-96b4-f78d8286713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887035bc-c4b5-4a7b-837a-05123521aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Images in the training set {train_X.shape[0]}\")\n",
    "print(f\"Images in the validation set {valid_X.shape[0]}\")\n",
    "print(f\"Images in the testing set {test_X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc46993-a877-47be-924c-9cebcd8cbf7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cd534-abac-43a7-9ca3-c20f52796aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll output 1 output node per class, consistent with multiclass problems\n",
    "NUM_OUTPUT_NODES = len(train_Y_one_hot[0])\n",
    "EPOCHES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae1b97-6de0-4e89-bd74-7d0ad6d957a9",
   "metadata": {},
   "source": [
    "### 3.1 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ed0de-3027-4577-9fdc-4931e67838ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Constructs the initial CNN\n",
    "initial_cnn = Sequential()\n",
    "\n",
    "# Input layer\n",
    "initial_cnn.add( Input( shape= (28,28,1) ) ) \n",
    "\n",
    "# Convolution - Max Pooling Layer Pairs\n",
    "initial_cnn.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "initial_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "initial_cnn.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "initial_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "initial_cnn.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "initial_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "# Feedforward Neural Network\n",
    "initial_cnn.add(Flatten())\n",
    "initial_cnn.add(Dense(128, activation='relu'))\n",
    "initial_cnn.add(Dense(NUM_OUTPUT_NODES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b41de0-5887-44dc-b46b-897ab26ce9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compiles & Displays it\n",
    "initial_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(),  \n",
    "                    metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")], )\n",
    "\n",
    "initial_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259689c-92c3-4393-b686-7b7a1507101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = initial_cnn.fit(train_X, train_label, validation_data=(valid_X, valid_label),\n",
    "                                batch_size=128, epochs=EPOCHES, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008940c-7065-4907-9489-d2cbf88ca86e",
   "metadata": {},
   "source": [
    "### 3.2 | Evaluate on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa04a5-9553-4c7e-973f-09ca5e1a18fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on training set\n",
    "print('Train loss:', hist.history[\"loss\"][-1])\n",
    "print('Train accuracy:', hist.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac5711-10c1-4a94-865f-1b12d5e0e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on testing set\n",
    "test_eval = initial_cnn.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe244b2-5c76-4815-9e87-c4e8125c3b1c",
   "metadata": {},
   "source": [
    "### 3.3 | Evaluate the CNN's Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f4352-c90e-43a3-b5e3-e33492a1d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, val_loss = hist.history[\"loss\"], hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12540a53-8d9d-484e-91e4-f226201a569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, val_acc = hist.history[\"accuracy\"], hist.history[\"val_accuracy\"]\n",
    "plot_performance(acc, val_acc, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ef04d-0210-4ab5-9c55-f69152171e1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4 | Your CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671bea65-7dc6-4ad1-9563-bb52ed8b2d24",
   "metadata": {},
   "source": [
    "### 4.0 | Section Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d213657-d440-47e8-9087-2b190aa7504d",
   "metadata": {},
   "source": [
    "The initial CNN from the previous section is pasted below, in each subsequent section. For each subsection, you'll be asked to modify one/more parameters of the neural network, and in the process, you'll learn more about what each parameter does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47c30d-6865-4736-89e3-a8d0a5d0ca56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1 | Task 1: Remove Max Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f5c4a-c4c6-408f-90c6-391374d991cb",
   "metadata": {},
   "source": [
    "#### 4.1.1 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f45a06-14b8-484d-950c-31bfe8232035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************\n",
    "#  EXERCISE\n",
    "# *****************************\n",
    "\n",
    "# Remove the max pooling layers of your CNN. What happens?\n",
    "\n",
    "\n",
    "# Constructs the initial CNN\n",
    "your_cnn = Sequential()\n",
    "\n",
    "# Input layer\n",
    "your_cnn.add( Input( shape= (28,28,1) ) ) \n",
    "\n",
    "# Convolutional Components\n",
    "your_cnn.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "# Feedforward Neural Network\n",
    "your_cnn.add(Flatten())\n",
    "your_cnn.add(Dense(128, activation='relu'))\n",
    "your_cnn.add(Dense(NUM_OUTPUT_NODES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf620042-ebca-4690-98a9-7ae2747e51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles & Displays it\n",
    "your_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(),  \n",
    "                    metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")], )\n",
    "\n",
    "your_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd547f74-dece-4429-ae6c-abb9ba7aa877",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_hist = your_cnn.fit(train_X, train_label, validation_data=(valid_X, valid_label),\n",
    "                                batch_size=128, epochs=EPOCHES, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51f3cc-d6df-4d78-a409-257dc1e04431",
   "metadata": {},
   "source": [
    "#### 4.1.2 | Evaluates your CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6365a-2cdd-4a55-9feb-b071dfe67059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on testing set\n",
    "your_test_eval = your_cnn.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "\n",
    "print(\"Your Model: \")\n",
    "print('Test loss:', your_test_eval[0])\n",
    "print('Test accuracy:', your_test_eval[1])\n",
    "\n",
    "print(\"\\nOriginal Model: \")\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97368c-e9a6-485a-af3e-339c16bced91",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, val_loss = your_hist.history[\"loss\"], your_hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed817e-2f59-4192-899f-aaba4add91af",
   "metadata": {},
   "source": [
    "#### 4.1.3 | Your Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb279401-c870-42ed-8c27-563ec2fab1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************\n",
    "# EXERCISE\n",
    "# ***************************\n",
    "\n",
    "# How is training time affected? How was performance affected?\n",
    "# Type your answer in the multi-line string below.\n",
    "\n",
    "'''\n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bf49d-5a76-484e-837d-929edd4dc53d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2 | Task 2: Add Another Convolutional Layer - Max Pooling Layer Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec1ed1-ae97-45f7-85ca-47b27cecc9a1",
   "metadata": {},
   "source": [
    "#### 4.2.1 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a275b92-43ed-48b9-b937-197a3b8ab516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# *****************************\n",
    "#  EXERCISE\n",
    "# *****************************\n",
    "\n",
    "# Add another convolutional layer\n",
    "# Add this AFTER the max pooling layer that appears immediately after the 128-neuron Max Pooling Layer\n",
    "# Make this however many neurons you want, provided it's less than or equal to 1024.\n",
    "\n",
    "try:\n",
    "    # Constructs the initial CNN\n",
    "    your_cnn = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    your_cnn.add(Input(shape=(28, 28, 1)))\n",
    "\n",
    "    # Convolutional Component\n",
    "    your_cnn.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu'))\n",
    "    your_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    your_cnn.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu'))\n",
    "    your_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    your_cnn.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu'))\n",
    "    your_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    your_cnn.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu'))\n",
    "    your_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Feedforward Neural Network\n",
    "    your_cnn.add(Flatten())\n",
    "    your_cnn.add(Dense(128, activation='relu'))\n",
    "    your_cnn.add(Dense(NUM_OUTPUT_NODES, activation='softmax'))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR. Your CNN cannot be constructed or compiled due to the following error: \\n{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c01ed2-cc25-4ecc-aa9a-5d4aeae744a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's no need to train this neural network ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e46ca-56c1-4bd0-9f67-03f3c903324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************\n",
    "# Exercise \n",
    "# ***************************\n",
    "\n",
    "# What just happened and why?\n",
    "# Hint: Look at the diagram of the initial CNN that appears at the start of this practicum\n",
    "# Type your answer below \n",
    "\n",
    "'''\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e410ef42-e021-4800-b9df-2296b6510667",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3 | Task 3: Invert the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4122e-13c8-4bd6-be2c-73fb17ae4d7c",
   "metadata": {},
   "source": [
    "#### 4.3.1 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f540c9a-917e-4d54-bf07-318b21ed1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************\n",
    "#  EXERCISE\n",
    "# *****************************\n",
    "\n",
    "# Invert the CNN such that there's more neurons closer to the input image, less neurons further out\n",
    "\n",
    "\n",
    "# Constructs the initial CNN\n",
    "your_cnn = Sequential()\n",
    "\n",
    "# Input layer\n",
    "your_cnn.add( Input( shape= (28,28,1) ) ) \n",
    "\n",
    "# Convolutional Component\n",
    "your_cnn.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "# Feedforward Neural Network\n",
    "your_cnn.add(Flatten())\n",
    "your_cnn.add(Dense(128, activation='relu'))\n",
    "your_cnn.add(Dense(NUM_OUTPUT_NODES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3afde-d4ec-49b0-a2d3-0d35eefa7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles & Displays it\n",
    "your_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(),  \n",
    "                    metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")], )\n",
    "\n",
    "your_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed290d-318e-4db6-acdb-5548065edbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_hist = your_cnn.fit(train_X, train_label, validation_data=(valid_X, valid_label),\n",
    "                                batch_size=128, epochs=EPOCHES, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a7d05-cbce-4905-8b3d-2240ff837c89",
   "metadata": {},
   "source": [
    "#### 4.3.2 | Evaluate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80578a6b-9550-477e-8ba4-f206799e1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on testing set\n",
    "your_test_eval = your_cnn.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "\n",
    "print(\"Your Model: \")\n",
    "print('Test loss:', your_test_eval[0])\n",
    "print('Test accuracy:', your_test_eval[1])\n",
    "\n",
    "print(\"\\nOriginal Model: \")\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1cf62-dce1-47fb-81d2-1a487d56af22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, val_loss = your_hist.history[\"loss\"], your_hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0d246-4ae9-4e28-adef-55884dfd9342",
   "metadata": {},
   "source": [
    "#### 4.3.3 | Your Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3cec95-0e76-40e9-88f0-7c64be6eed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************\n",
    "# EXERCISE\n",
    "# **********************\n",
    "\n",
    "\n",
    "# What happened to the model's performance? Did anything else happen?\n",
    "# Type your answer in the multi-line string below\n",
    "\n",
    "'''\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace3335-5916-439e-8195-13d8db5ef5e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.4 | Task 4: Add Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df66bfe-4414-4a57-a302-f817a832a896",
   "metadata": {},
   "source": [
    "#### 4.4.1 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38241a8b-a0f8-48b9-b54e-0e2cf0557d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************\n",
    "#  EXERCISE\n",
    "# *****************************\n",
    "\n",
    "# Dropout layers are extremely common in CNNs because they reduce overfitting without impairing performance.\n",
    "# Why don't you add a dropout layer after each MaxPooling layer below?\n",
    "# I did the first for you. \n",
    "# Feel free to adjust the decimal within the dropout parameter. It's the percentage of neurons in the previous layer that'll be removed.\n",
    "\n",
    "\n",
    "# Constructs the initial CNN\n",
    "your_cnn = Sequential()\n",
    "\n",
    "# Input layer\n",
    "your_cnn.add( Input( shape= (28,28,1) ) ) \n",
    "\n",
    "# Convolutional Component\n",
    "your_cnn.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "your_cnn.add( Dropout(0.50) ) # Feel free to adjust 0.25 to any value between 0 and 1.00\n",
    "\n",
    "your_cnn.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') )\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "# Feedforward Neural Network\n",
    "your_cnn.add(Flatten())\n",
    "your_cnn.add(Dense(128, activation='relu'))\n",
    "your_cnn.add(Dense(NUM_OUTPUT_NODES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6c7ae-5968-4503-abe0-e8cd8a83ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(),  \n",
    "                    metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")], )\n",
    "\n",
    "your_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520549f-d6d7-445d-ac0b-bef4df584c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_hist = your_cnn.fit(train_X, train_label, validation_data=(valid_X, valid_label),\n",
    "                                batch_size=128, epochs=EPOCHES, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03af40-511e-4688-a460-fdaccb00caf0",
   "metadata": {},
   "source": [
    "#### 4.4.2 | Evaluate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f92fb2-b31e-439d-b099-be70e5ae3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on testing set\n",
    "your_test_eval = your_cnn.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "\n",
    "print(\"Your Model: \")\n",
    "print('Test loss:', your_test_eval[0])\n",
    "print('Test accuracy:', your_test_eval[1])\n",
    "\n",
    "print(\"\\nOriginal Model: \")\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126b47b-b318-48f2-a45f-4f89912ac713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, val_loss = your_hist.history[\"loss\"], your_hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b0b1d-6c86-4f79-bdb2-4946b8483c3e",
   "metadata": {},
   "source": [
    "#### 4.4.3 | Your Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769872d-baa7-49c1-9c50-a603d3739b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************\n",
    "# EXERCISE\n",
    "# ****************************\n",
    "\n",
    "# What happened to your model's performance?\n",
    "# Did dropout help or hurt your model's performance on the testing set? Why?\n",
    "\n",
    "'''\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456efde-2a7f-4184-98bc-3a36b99f9683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5 | Freestyling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a311332-508e-4edb-b8d4-909948aba52d",
   "metadata": {},
   "source": [
    "### 5.0 | Section Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be67d3-95e0-422a-8f67-83cbb0557647",
   "metadata": {},
   "source": [
    "This section is arrayed just like the individual task sections in §4.0. However, you're free to make whatever changes to the original CNN that you wish. Just make sure your CNN compiles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828c6bd-03f1-4483-84cd-6402b3b261c4",
   "metadata": {},
   "source": [
    "### 5.1 | Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d388f4-d82e-4163-89a6-ed700494d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs the initial CNN\n",
    "your_cnn = Sequential()\n",
    "\n",
    "# Input layer\n",
    "your_cnn.add( Input( shape= (28,28,1) ) ) \n",
    "\n",
    "# Convolutional Component\n",
    "your_cnn.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') ) # Change activation function\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') ) # Change activation function\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "your_cnn.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='leaky_relu') ) # Change activation function\n",
    "your_cnn.add( MaxPooling2D(pool_size=(2, 2) ) )\n",
    "\n",
    "# Feedforward Neural Network\n",
    "your_cnn.add(Flatten())\n",
    "your_cnn.add(Dense(128, activation='relu')) # Change activation function\n",
    "your_cnn.add(Dense(NUM_OUTPUT_NODES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963289aa-5ac6-431b-8046-2f6ca998c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(),  \n",
    "                    metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")], )\n",
    "\n",
    "your_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ebedf-b5a3-4dd5-9ae0-b3d157607e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_hist = your_cnn.fit(train_X, train_label, validation_data=(valid_X, valid_label),\n",
    "                                batch_size=128, epochs=EPOCHES, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0551e9-41dd-4c6c-a136-06e53bf4eb8f",
   "metadata": {},
   "source": [
    "### 5.2 | Evaluate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7b074-b65d-4ac0-bd1d-1c14efe284f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on testing set\n",
    "your_test_eval = your_cnn.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "\n",
    "print(\"Your Model: \")\n",
    "print('Test loss:', your_test_eval[0])\n",
    "print('Test accuracy:', your_test_eval[1])\n",
    "\n",
    "print(\"\\nOriginal Model: \")\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d57dc-5f9f-4ca7-9ada-d65f2018f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, val_loss = your_hist.history[\"loss\"], your_hist.history[\"val_loss\"]\n",
    "plot_performance(loss, val_loss, \"Loss (Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d8721-0447-4d3e-a712-9cb9abc58c80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6 | Detailed CNN Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3c857-c813-4c28-bea2-c12d23936b36",
   "metadata": {},
   "source": [
    "### 6.1 | Test Set Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541bac9-9166-469c-bb3c-c8ac3a451306",
   "metadata": {},
   "source": [
    "Let's retrieve the CNN's performance on the testing set, which was calcualted earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a4eb3-61ab-4b58-b2fe-808dd3d30d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb00ac5-7eb2-423e-a018-94ddf3a2fbc5",
   "metadata": {},
   "source": [
    "### 6.2 | Calculate Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb4742-1338-426a-9741-fe67b9999e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the images that the CNN correctly predicted\n",
    "\n",
    "# First, we'll have the model make predictions on the test image\n",
    "predicted_classes = initial_cnn.predict(test_X)\n",
    "\n",
    "# However, each prediction contains 10 probabilities - one probability per class\n",
    "# The neural network selects the prediction with the highest probability\n",
    "print(\"Prediction for the first image: \")\n",
    "predicted_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0083e5de-eeaf-4f6a-b048-c845422219c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argmax will select the class with the highest probability\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "print(\"Predicted class for the first image: \")\n",
    "predicted_classes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607d0ae-2c4e-464d-94e7-339455cee388",
   "metadata": {},
   "source": [
    "### 6.3 | Display Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3e3a6-3dec-4596-adda-bb51e3378857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies the correct images\n",
    "correct = np.where(predicted_classes==test_Y)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "\n",
    "# Displays the first nine via MatPlotLib\n",
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], test_Y[correct]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a60b3-e960-42c8-bc46-3796e58e1210",
   "metadata": {},
   "source": [
    "### 6.4 | Display Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96308baa-1740-4fef-863b-2656b3fac26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes!=test_Y)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], test_Y[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7c89d-2ba1-4f30-a1c6-d57cdccbf9de",
   "metadata": {},
   "source": [
    "### 6.5 | Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe14af-7502-4020-9422-8fdb8199a54d",
   "metadata": {},
   "source": [
    "Now that we have the predicted classes nicely formatted, we can get evaluation metrics in detail. The names of the clothes that correspond to each class ID were https://www.kaggle.com/datasets/zalando-research/fashionmnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7f1da-3e14-4459-ac1c-74988eaeaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807aa20-9f44-429a-9cf6-78d340b6a8cd",
   "metadata": {},
   "source": [
    "You can see that the classifier is underperforming for class 6 regarding both precision and recall. For class 0 and class 2, the classifier is lacking precision. Also, for class 4, the classifier is slightly lacking both precision and recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
